# multi-modal-application-development
项目链接：https://loving-basement-33d.notion.site/6bdba78ea04d457f80890dd7c1fb3c10?pvs=4

## 需求文档分工
task1：1 2
task2: 3
task3: 4 5
task4: 6 7 8
模仿之前发的文档写的。

# 项目概述

图文助手是一款基于多模态学习模型的一套完整的从客户端到服务端的**工具平台**。

通过深度学习训练多模态学习模型，实现对文本和图像的编码、匹配进而双向检索，并在此基础上开发应用。

### 文字到图片的检索

用户用于检索的图片将被预先通过预训练的图像编码网络进行编码，并存储在后端数据库中。

用户在客户端输入的文字，首先通过预训练的文本编码网络进行编码。

在云端通过检索模型找到与文字语义匹配度最高的图片并返回索引至客户端。

可拓展应用场景：

1. 为用户的相册提供个性化管理
2. 可以调用文心一言的接口生成简单图片，集成到客户端
3. 可以集成任何跟图片有关的功能。

### 图片到文字的生成

用户通过将需要检索图片上传到云端，在云端对图像进行编码，然后利用训练的模型得到文本的标签描述。

可拓展应用场景：

1. 集成到为盲人设计的实时场景识别设备，可以辅助盲人生活。
2. 图片标签化可以用于数据标注（如果准确率和鲁棒性高的话）
3. 一键图片配文可以集成到社交平台和短视频平台

## 怎么做？

> 必须要有的：
> 
1. 一个最基本的安卓桌面app，能够获取相册权限，能够在本地将相册中的图片数据编码然后发送到服务器。能够将文本编码发送到服务器。
2. 服务器部署的模型能够进行最简单的根据图片生成标签，根据文本检索图片。
3. 一个数据库

> 项目最终最简单的实践：
> 
1. 学移动应用开发，能做出有一个简单的界面（静态的，非响应式的）的app。
2. 学http、mqtt等常见通信协议，最简单最基础的http请求怎么写，用于发送数据。
3. 后端的服务器租赁，能够部署一个最简单的模型，实现检索，能够监听http（mqtt）请求并发送数据。
4. 编写一个简单的数据库，用于存储文本编码、图片编码和对应标签。

> **最简单的效果：**
> 

→用户安装app

→动态请求相册权限

→初始化数据库（将图片编码发送到数据库）

- 文本到图片
    
    →用户输入文本描述
    
    →编码后的文本数据作为HTTP请求的一部分，使用POST请求上传到服务器
    
    →服务器调用检索模型，检索出与文本描述相似度最高的前5张图片，返回索引
    
    →根据索引，app端将对应图片展示给用户
    

- 图片到文本
    
    →用户选择图片描述功能，选择图片
    
    →app返回图片编码
    
    →服务器根据图片特征在文本空间中找到匹配的描述
    
    →服务器返回描述
    
    →app端将描述展示给用户
    

## 关于课程

因为只是一个课程实践，而且时间也很短，前后端我们都尽可能简单写一下就行，最后能跑通整个流程展示就行，（其实跑不通也能通过各种手段看起来跑通了 🤐），重要的是把文档之类的写详细一点就好了。这个方向也可能有真正有意义的产出，只不过要投入的精力和时间可能会超出我们目前的能力和承受范围，（如果我们最后做的过程比较顺利可以考虑做更好一些），总之就是不用太焦虑能不能做好，简单版本的话我感觉甚至集中几天精力就可以写完 😂 🫢。
